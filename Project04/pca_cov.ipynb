{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR NAME HERE**\n",
    "\n",
    "Spring 2020\n",
    "\n",
    "CS 251: Data Analysis and Visualization\n",
    "\n",
    "Project 4: Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import pca_cov\n",
    "\n",
    "plt.style.use(['seaborn-colorblind', 'seaborn-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "\n",
    "# Automatically reload external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "In your implementations, only the following \"high level\" `scipy`/`numpy` functions can be used:\n",
    "\n",
    "- `np.linalg.eig`\n",
    "\n",
    "**NOTE:** The numpy functions that you have been using so far are fine to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Principal component analysis using the covariance matrix\n",
    "\n",
    "In this task, you will implement principal component analysis (PCA) using the covariance matrix method, test your code, plot the results on the Iris dataset, then run PCA and analyze on several other datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Import Iris data\n",
    "\n",
    "- In the below cell, load in the Iris dataset into a pandas DataFrame (note, this version of iris does not have the data type row — going forward, csv files we work with won't have this `type` row).\n",
    "- Print out the head (only showing the first 5 data samples).\n",
    "- Create an `PCA` object called `pca` based on the DataFrame object that you just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code should print something that looks like this (with fancier formatting):\n",
    "\n",
    "    sepalLength\tsepalWidth\tpetalLength\tpetalWidth\tspecies\n",
    "    0\t5.1\t3.5\t1.4\t0.2\t0\n",
    "    1\t4.9\t3.0\t1.4\t0.2\t0\n",
    "    2\t4.7\t3.2\t1.3\t0.2\t0\n",
    "    3\t4.6\t3.1\t1.5\t0.2\t0\n",
    "    4\t5.0\t3.6\t1.4\t0.2\t0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Implement PCA\n",
    "\n",
    "Implement and test the following methods necessary to perform PCA in `pca_cov.py`.\n",
    "\n",
    "- `covariance_matrix`: Computes the covariance matrix of data\n",
    "- `compute_prop_var`: Computes the proportion variance accounted for by the principal components (PCs).\n",
    "- `compute_cum_var`: Computes the *cumulative* proportion variance accounted for by the PCs.\n",
    "- `pca`: Method to perform PCA on the data\n",
    "- `elbow_plot` (**answer Question 1**)\n",
    "- `pca_project`: Project the data into PCA space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Test `covariance_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test covariance here\n",
    "np.random.seed(0)\n",
    "d = np.random.randn(100, 3)\n",
    "cov_mat = pca.covariance_matrix(d)\n",
    "print(f'Your covariance matrix has shape {cov_mat.shape} and should be (3, 3)')\n",
    "print(f'Your covariance matrix is:\\n{cov_mat} and should be\\n[[ 1.07359 -0.06483  0.10006]\\n [-0.06483  0.98552 -0.03553]\\n [ 0.10006 -0.03553  0.97774]]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Tes `prop_var`\n",
    "\n",
    "Takes eigenvalues ordered large-to-small and computes the proportion of the total variance account for by the $k^{th}$ principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prop_var here\n",
    "np.random.seed(0)\n",
    "test_evals = np.sort(np.random.uniform(size=(10,)))[::-1]\n",
    "prop_var = pca.compute_prop_var(test_evals)\n",
    "print(f'Your list is actually a Python list (as it should be)? {isinstance(prop_var, list)}')\n",
    "print(f'Your proportion variance list length is {len(prop_var)} and should be 10')\n",
    "print(f'Your proportion variance list begins with\\n{prop_var[:2]} and it should be\\n[0.15649813681155653, 0.1448232917174111]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Test `compute_cum_var`\n",
    "\n",
    "Takes proportion variance for principal components, ordered large-to-small, and computes the cumulative sum (cumulative variance accounted for by the first $k$ principal components)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accum_var here\n",
    "np.random.seed(0)\n",
    "test_evals = np.sort(np.random.uniform(size=(10,)))[::-1]\n",
    "prop_var = pca.compute_prop_var(test_evals)\n",
    "accum_var = pca.compute_cum_var(prop_var)\n",
    "print(f'Your list is actually a Python list (as it should be)? {isinstance(accum_var, list)}')\n",
    "print(f'Your cumulative variance list length is {len(accum_var)} and should be 10')\n",
    "print(f'Your cumulative variance list begins with\\n{accum_var[:2]} and should be\\n[0.15649813681155653, 0.3013214285289676]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) Test `pca`\n",
    "\n",
    "Performs PCA using the covariance matrix method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pca (no normalization) here\n",
    "iris_headers = list(iris_data.columns[:-1])\n",
    "pca.pca(iris_headers)\n",
    "\n",
    "# test that instance variable shape are correct\n",
    "print(f'There are {len(pca.vars)} vars in Iris PCA and there should be 4.')\n",
    "print(f'The original PCA data has shape {pca.A.shape} and should be (149, 4).')\n",
    "print(f'Eigenvector shape: {pca.e_vecs.shape} should be (4, 4).\\nEigenvalue shape: {pca.e_vals.shape} should be (4,).')\n",
    "print(f'Length of proportion variance account for: {len(pca.get_prop_var())} should be 4.')\n",
    "print(f'Length of cumulative proportion variance account for: {len(pca.get_cum_var())} should be 4.')\n",
    "print()\n",
    "\n",
    "# Test values\n",
    "print(f\"Your vars in Iris PCA:\\n{pca.vars}  and they should be\\n['sepalLength', 'sepalWidth', 'petalLength', 'petalWidth']\")\n",
    "print(f'Your eigenvectors:\\n{pca.e_vecs}. They should be\\n[[ 0.36139 -0.65659 -0.58203  0.31549]\\n [-0.08452 -0.73016  0.59791 -0.31972].\\n [ 0.85667  0.17337  0.07624 -0.47984]\\n[ 0.35829  0.07548  0.54583  0.75366]].')\n",
    "print(f'Your eigenvalues:\\n{pca.e_vecs}. They should be\\n[[ 0.36139 -0.65659 -0.58203  0.31549]\\n [-0.08452 -0.73016  0.59791 -0.31972].\\n [ 0.85667  0.17337  0.07624 -0.47984]\\n[ 0.35829  0.07548  0.54583  0.75366]].')\n",
    "print(f'Your eigenvalues:\\n{pca.e_vals}. They should be\\n[4.22824 0.24267 0.07821 0.02384]')\n",
    "print(f'Cumulative proportion variance account for:\\n{pca.get_cum_var()}. It should be\\n[0.924618723201727, 0.9776852063187949, 0.9947878161267245, 0.9999999999999999] .')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pca (normalization) here\n",
    "iris_headers = list(iris_data.columns[:-1])\n",
    "pca.pca(iris_headers, normalize=True)\n",
    "\n",
    "# test that instance variable shape are correct\n",
    "print(f'There are {len(pca.vars)} vars in Iris PCA and there should be 4.')\n",
    "print(f'The original PCA data has shape {pca.A.shape} and should be (149, 4).')\n",
    "print(f'Eigenvector shape: {pca.e_vecs.shape} should be (4, 4).\\nEigenvalue shape: {pca.e_vals.shape} should be (4,).')\n",
    "print(f'Length of proportion variance account for: {len(pca.get_prop_var())} should be 4.')\n",
    "print(f'Length of cumulative proportion variance account for: {len(pca.get_cum_var())} should be 4.')\n",
    "print(f'Data min/max is {pca.A.min()}/{pca.A.max()} should be 0.0/1.0')\n",
    "print()\n",
    "\n",
    "# Some test values\n",
    "print(f'Your eigenvalues:\\n{pca.e_vals}. They should be\\n[0.23245 0.03247 0.0096  0.00176].')\n",
    "print(f'Cumulative proportion variance account for:\\n{pca.get_cum_var()}. It should be\\n[0.8413603821315434, 0.9588784639918418, 0.9936140780797744, 1.0].')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (v) Test `elbow_plot`\n",
    "\n",
    "Visualize the cumulative proportion variance accounted for by the first $k$ principal components.\n",
    "\n",
    "**Make sure that you have the normalized PCA in memory before proceeding (the last cell of test code above)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test elbow plot\n",
    "pca.elbow_plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Based on the Iris elbow plot, how many principle components would you drop. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1 answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (vi) Test `pca_project`\n",
    "\n",
    "Project the data onto a list of the top $2$ principal components (`pcs_to_keep = [0, 1]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot your PCA projected Iris data\n",
    "\n",
    "- In the cell below, create a scatterplot of your PCA projected data.\n",
    "- Label the x and y axes appropriately.\n",
    "\n",
    "If everything goes well, you should see two distinct clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) Dropping different pairs of principal components\n",
    "\n",
    "- In the cell below, create a \"high quality\" 2x2 subplots grid of scatterplots that drops different consective PCs from the data, then project onto the remaining PCs.\n",
    "\n",
    "The 2x2 plots should keep:\n",
    "- (top-left) PCs [2, 3]\n",
    "- (top-right) PCs [1, 2]\n",
    "- (bottom-left) PCs [3, 0]\n",
    "- (bottom-right) PCs [0, 1]\n",
    "\n",
    "High quality means\n",
    "- x and y axis label indicating the PC (e.g. PC0)\n",
    "- title indicating the PCs shown in the plot\n",
    "\n",
    "You may have to adjust the font/figure sizes to make things legiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Interpret what the 2x2 grid of plots tells us about keeping different PCs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2 answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d) Loading plot (or heatmap for sections A/C)\n",
    "\n",
    "Visualize how the top two principal components relate to original data variables.\n",
    "\n",
    "- Implement `loading_plot` (or heatmap for sections A/C) in `pca_cov.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `loading_plot` (or heatmap for sections A/C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.loading_plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** What do the loadings (or heatmap for sections A/C) tell us what the first two PCs measure, with respect to the original data axes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3 answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** What do the loadings (or heatmap for sections A/C) tell us about correlations among the original data axes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4 answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1e) Reconstruct data based on PCs\n",
    "\n",
    "- In `pca_cov.py`, implement `pca_then_project_back`, which projects the data to PCA space, keeping only the top $k$ PCs, then projects from PCA space back onto the original data space.\n",
    "- In the cell below, create a scatter plot of the two data variables 'sepalLength', 'sepalWidth' of the Iris data **normalized separately**.\n",
    "- In the 2nd cell below, do PCA on the normalized Iris data and create a 2x2 grid of scatter plots showing the data reconstruction of the 1st two data variables ('sepalLength', 'sepalWidth' — *these are what your axis labels should be*) when keeping the top 1, 2, 3, or 4 (all) principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original iris data normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x2 grid of scatter plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** How well does each of the re-projections compress the original data? Briefly interpret what the above 2x2 grid means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5 answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: PCA on Australia dataset and one other dataset\n",
    "\n",
    "Do PCA on:\n",
    "- the Australia dataset\n",
    "- one other dataet of your choice\n",
    "\n",
    "In the cells below, include at minimum\n",
    "\n",
    "- Elbow plot of cumulative variance accounted for by first $k$ principal components.\n",
    "- Written description of your choice of number of PCs preserved and why.\n",
    "- Visualization (plot) of PCA projected data on 1st two PCs.\n",
    "- Loading plot (or heatmap for sections A/C) of the 1st two PCs. Interpret the meaning of each vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a) Australia dataset PCA\n",
    "\n",
    "Do a PCA (**with data normalization**), but include only the following variables in the data matrix:\n",
    "\n",
    "    premin, premax, salmin, salmax, minairtemp, maxairtemp, minsst, maxsst, minsoilmoist, maxsoilmoist, and runoffnew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b) Other dataset PCA\n",
    "\n",
    "**Make sure you describe what the dataset is, what variables are, where you got it.**\n",
    "\n",
    "Include at minimum below:\n",
    "\n",
    "- Elbow plot of cumulative variance accounted for by first $k$ principal components.\n",
    "- Written description of your choice of number of PCs preserved and why.\n",
    "- Visualization (plot) of PCA projected data on 1st two PCs.\n",
    "- Loading plot (or heatmap for sections A/C) of the 1st two PCs. Interpret the meaning of each vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
